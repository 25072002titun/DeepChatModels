{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reformatting Ubuntu Dialogue Corpus for Chatbot Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random facts [from paper](https://arxiv.org/abs/1506.08909):\n",
    "* 2-way (dyadic) conversation, as opposed to multi-participant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "DATA_DIR = '/home/brandon/terabyte/Datasets/ubuntu_dialogue_corpus/'\n",
    "TRAIN_PATH = DATA_DIR + 'src/train.csv'\n",
    "VALID_PATH = DATA_DIR + 'src/valid.csv'\n",
    "TEST_PATH = DATA_DIR + 'src/test.csv'\n",
    "\n",
    "def get_training():\n",
    "    \"\"\"Returns dataframe data from train.csv \"\"\"\n",
    "    # First, we need to load the data directly into a dataframe from the train.csv file. \n",
    "    df_train = pd.read_csv(TRAIN_PATH)\n",
    "    # Remove all examples with label = 0. (why would i want to train on false examples?)\n",
    "    df_train = df_train.loc[df_train['Label'] == 1.0]\n",
    "    # Don't care about the pandas indices in the df, so remove them.\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_train = df_train[df_train.columns[:2]]\n",
    "    return df_train\n",
    "\n",
    "def get_validation():\n",
    "    \"\"\"Returns data from valid.csv \"\"\"\n",
    "    # First, we need to load the data directly into a dataframe from the train.csv file. \n",
    "    df_valid = pd.read_csv(VALID_PATH)\n",
    "    first_two_cols = df_valid.columns[:2]\n",
    "    df_valid = df_valid[first_two_cols]\n",
    "    df_valid.columns = ['Context', 'Utterance']\n",
    "    return df_valid\n",
    "\n",
    "df_train = get_training()\n",
    "df_valid = get_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Functions for Visualization and Reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now get all of the data in a single string and make a 'vocabulary' (unique words). \n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "import pdb\n",
    "\n",
    "def print_single_turn(turn: str):\n",
    "    as_list_of_utters = turn.split('__eou__')[:-1]\n",
    "    for idx_utter, utter in enumerate(as_list_of_utters):\n",
    "        print(\"\\t>>>\", utter)\n",
    "\n",
    "def print_conversation(df, index=0):\n",
    "    \"\"\"Display the ith conversation in nice format.\"\"\"\n",
    "    \n",
    "    # Get the row identified by 'index'. \n",
    "    context_entry = df['Context'].values[index]\n",
    "    target        = df['Utterance'].values[index]\n",
    "    \n",
    "    # Split returns a blank last entry, so don't store.\n",
    "    turns = context_entry.split('__eot__')[:-1]\n",
    "    print('--------------------- CONTEXT ------------------- ')\n",
    "    for idx_turn, turn in enumerate(turns):\n",
    "        print(\"\\nUser {}: \".format(idx_turn % 2))\n",
    "        print_single_turn(turn)\n",
    "    print('\\n--------------------- RESPONSE ------------------- ')\n",
    "    print(\"\\nUser {}: \".format(len(turns) % 2))\n",
    "    print_single_turn(target)\n",
    "        \n",
    "def get_user_arrays(df):\n",
    "    \"\"\"Returns two arrays of every other turn. \n",
    "    Specifically:\n",
    "        len(returned array) is number of rows in df.  I SURE HOPE NOT!\n",
    "        each entry is a numpy array. \n",
    "        each numpy array contains utterances as entries. \n",
    "    \"\"\"\n",
    "    userOne = []\n",
    "    userTwo = []\n",
    "    contexts = df['Context'].values\n",
    "    targets  = df['Utterance'].values\n",
    "    assert(len(contexts) == len(targets))\n",
    "    \n",
    "    for i in range(len(contexts)):\n",
    "        # combined SINGLE CONVERSATION ENTRY of multiple turns each with multiple utterances.\n",
    "        list_of_turns = contexts[i].split('__eot__')[:-1] + [targets[i]]\n",
    "        \n",
    "        # make sure even number of entries\n",
    "        if len(list_of_turns) % 2 != 0:\n",
    "            list_of_turns = list_of_turns[:-1]\n",
    "            \n",
    "        # strip out the __eou__ occurences (leading space bc otherwise would result in two spaces)\n",
    "        re.sub(' __eou__', '', 'mu butthole __eou__ fucking jews __eou__ obama')\n",
    "        list_of_turns = [re.sub(' __eou__', '', t) for t in list_of_turns]\n",
    "        \n",
    "        userOneThisConvo = list_of_turns[0::2]\n",
    "        userTwoThisConvo = list_of_turns[1::2]\n",
    "        \n",
    "        userOne += userOneThisConvo \n",
    "        userTwo += userTwoThisConvo\n",
    "        \n",
    "    assert(len(userOne) == len(userTwo))\n",
    "    return userOne, userTwo\n",
    "\n",
    "def save_to_file(fname, arr):\n",
    "    with open(DATA_DIR+fname,\"w\") as f:\n",
    "        for line in arr:\n",
    "            f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train has 1000000 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think we could import the old comments via r...</td>\n",
       "      <td>basically each xfree86 upload will NOT force u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I 'm not suggesting all - only the ones you mo...</td>\n",
       "      <td>oh ? oops . __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon all __eou__ not entirely related to ...</td>\n",
       "      <td>we 'll have a BOF about this __eou__ so you 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting __eou__ grub-install worked with /...</td>\n",
       "      <td>i fully endorse this suggestion &lt; /quimby &gt; __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and because Python gives Mark a woody __eou__ ...</td>\n",
       "      <td>( i thought someone was going to make a joke a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  i think we could import the old comments via r...   \n",
       "1  I 'm not suggesting all - only the ones you mo...   \n",
       "2  afternoon all __eou__ not entirely related to ...   \n",
       "3  interesting __eou__ grub-install worked with /...   \n",
       "4  and because Python gives Mark a woody __eou__ ...   \n",
       "\n",
       "                                           Utterance  \n",
       "0  basically each xfree86 upload will NOT force u...  \n",
       "1                                oh ? oops . __eou__  \n",
       "2  we 'll have a BOF about this __eou__ so you 'r...  \n",
       "3  i fully endorse this suggestion < /quimby > __...  \n",
       "4  ( i thought someone was going to make a joke a...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"df_train has\", len(df_train), \"rows.\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One: I 'm not suggesting all - only the ones you modify . \n",
      "Two:  ok , it sounds like you 're agreeing with me , then though rather than `` the ones we modify '' , my idea is `` the ones we need to merge '' \n",
      "\n",
      "One: afternoon all not entirely related to warty , but if grub-install takes 5 minutes to install , is this a sign that i should just retry the install : ) \n",
      "Two:  here \n",
      "\n",
      "One:  you might want to know that thinice in warty is buggy compared to that in sid \n",
      "Two:  and apparently GNOME is suddently almost perfect ( out of the thinice problem ) , nobody report bugs : -P I do n't get your question , where do you want to paste ? \n",
      "\n",
      "One:  can i file the panel not linking to eds ? : ) \n",
      "Two:  are you using alt ? or the windows key ? wait for the gnome-themes , component will be added \n",
      "\n",
      "One:  i just restarted X and now nautilus wo n't show the desktop : ( hal is n't starting : ( \n",
      "Two:  do you think we have any interest to have hal support turned on in gnome-vfs at this point ? It increases the sources of problems for no real benefit imho ... \n",
      "\n",
      "One:  is it a known bug that g-s-t does n't know what distribution its running on ? are there any changes to desktop-file-utils you 've got hidden away ? \n",
      "Two:  somebody should really kick that guy *hard* I 've added a build-dep on libxt-dev in warty for zenity \n",
      "\n",
      "One:  arse . xt-dev ? i added libx11-dev so just libxt-dev or libxt and libx11 ? for future note , the xmodmap line in that X sticky-super fixes the problem for me \n",
      "Two:  we have planned to speak about menu organisation during the 2 weeks I need we do n't need to force it ? \n",
      "\n",
      "One:  was away , you said ? nope \n",
      "Two:  the warty repository ok , fine . Thanks nice to get packages update every 30min instead once a day , is n't it : ) \n",
      "\n",
      "One:  you 'll be glad to know i 've fixed my missing arrows in thinice bug \n",
      "Two:  I 've uploaded the gnome-vfs without hal support should be available rsn \n",
      "\n",
      "One:  should g2 in ubuntu do the magic dont-focus-window tricks ? join the gang , get an x-series thinkpad sj has hung on my box , again . what is monday mornings discussion actually about ? \n",
      "Two: we 'll have a BOF about this so you 're coming tomorrow ?\n",
      "\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "oneTest, twoTest = get_user_arrays(df_train.ix[1:2])\n",
    "for one, two in zip(oneTest, twoTest):\n",
    "    print('One:', one)\n",
    "    print('Two:', two)\n",
    "    print()\n",
    "\n",
    "print(len(oneTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- CONTEXT ------------------- \n",
      "\n",
      "User 0: \n",
      "\t>>> interesting \n",
      "\t>>>  grub-install worked with / being ext3 , failed when it was xfs \n",
      "\t>>>  i thought d-i installed the relevant kernel for your machine . i have a p4 and its installed the 386 kernel \n",
      "\t>>>  holy crap a lot of stuff gets installed by default : ) \n",
      "\t>>>  YOU ARE INSTALLING VIM ON A BOX OF MINE \n",
      "\t>>>  ; ) \n",
      "\n",
      "User 1: \n",
      "\t>>>  more like osx than debian ; ) \n",
      "\t>>>  we have a selection of python modules available for great justice ( and python development ) \n",
      "\n",
      "User 0: \n",
      "\t>>>  2.8 is fixing them iirc \n",
      "\n",
      "User 1: \n",
      "\t>>>  pong \n",
      "\t>>>  vino will be in \n",
      "\t>>>  enjoying ubuntu ? \n",
      "\n",
      "User 0: \n",
      "\t>>>  told me to come here \n",
      "\t>>>  suggested thursday as a good day to come \n",
      "\n",
      "User 1: \n",
      "\t>>>  we froze versions a while back : ) \n",
      "\t>>>  you coming today or thursday ? \n",
      "\t>>>  we 're considering shifting it \n",
      "\t>>>  yay \n",
      "\t>>>  enjoying ubuntu ? \n",
      "\t>>>  usplash ! \n",
      "\n",
      "User 0: \n",
      "\t>>>  thats the one \n",
      "\n",
      "User 1: \n",
      "\t>>>  so i saw your email with the mockup at the airport , but it has n't appeared now that i 've pulled my mail : | \n",
      "\n",
      "User 0: \n",
      "\t>>>  i 've got a better one now too , give me a minute \n",
      "\t>>>  we 've got rh9 installed on most desktops . you want me to look at up2date , right ? \n",
      "\n",
      "User 1: \n",
      "\t>>>  aha ! no , the gui thingy \n",
      "\t>>>  it 's more wizardy \n",
      "\t>>>  so the first page is okayish \n",
      "\t>>>  we can do a whole load better on the second page ( icons , translated descriptions ) \n",
      "\t>>>  but that 's the kind of thing i was thinking about \n",
      "\t>>>  ( a single big treeview would get very scary , very quickly ) \n",
      "\t>>>  sure it 's not a hurricane ? \n",
      "\n",
      "User 0: \n",
      "\t>>>  i think experimental is getting 2.8 too \n",
      "\t>>>  let him work on # 1217 : ) \n",
      "\n",
      "User 1: \n",
      "\t>>>  we call it 'universe ' ; ) \n",
      "\t>>>  haha \n",
      "\t>>>  ooh , totally \n",
      "\n",
      "User 0: \n",
      "\t>>>  i want it on in sarge too but nobody else agrees \n",
      "\n",
      "--------------------- RESPONSE ------------------- \n",
      "\n",
      "User 1: \n",
      "\t>>> i fully endorse this suggestion < /quimby > \n",
      "\t>>>  how did your reinstall go ? \n"
     ]
    }
   ],
   "source": [
    "print_conversation(df_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userOne, userTwo = get_user_arrays(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_to_file(\"train_from.txt\", userOne)\n",
    "save_to_file(\"train_to.txt\", userTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_valid has 19560 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Any ideas on how lts will be released ? __eou_...</td>\n",
       "      <td>We are talking 12.04 not 10.04 __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how much hdd use ubuntu default install ? __eo...</td>\n",
       "      <td>thats why i ask how much is default install ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in my country its nearly the 27th __eou__ when...</td>\n",
       "      <td>thanx __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it 's not out __eou__ __eot__ they probabaly a...</td>\n",
       "      <td>waiting for many things to be setup __eou__ fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are the ext4 drivers stable ? __eou__ __eot__ ...</td>\n",
       "      <td>you sound like it 's updating to skynet . ; ) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  Any ideas on how lts will be released ? __eou_...   \n",
       "1  how much hdd use ubuntu default install ? __eo...   \n",
       "2  in my country its nearly the 27th __eou__ when...   \n",
       "3  it 's not out __eou__ __eot__ they probabaly a...   \n",
       "4  are the ext4 drivers stable ? __eou__ __eot__ ...   \n",
       "\n",
       "                                           Utterance  \n",
       "0             We are talking 12.04 not 10.04 __eou__  \n",
       "1  thats why i ask how much is default install ? ...  \n",
       "2                                      thanx __eou__  \n",
       "3  waiting for many things to be setup __eou__ fi...  \n",
       "4  you sound like it 's updating to skynet . ; ) ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"df_valid has\", len(df_valid), \"rows.\")\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userOne, userTwo = get_user_arrays(df_valid)\n",
    "save_to_file(\"valid_from.txt\", userOne)\n",
    "save_to_file(\"valid_to.txt\", userTwo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
