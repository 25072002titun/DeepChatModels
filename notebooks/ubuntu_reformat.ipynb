{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reformatting Ubuntu Dialogue Corpus for Chatbot Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random facts [from paper](https://arxiv.org/abs/1506.08909):\n",
    "* 2-way (dyadic) conversation, as opposed to multi-participant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "DATA_DIR = '/home/brandon/terabyte/Datasets/ubuntu_dialogue_corpus/'\n",
    "TRAIN_PATH = DATA_DIR + 'src/train.csv'\n",
    "VALID_PATH = DATA_DIR + 'src/valid.csv'\n",
    "TEST_PATH = DATA_DIR + 'src/test.csv'\n",
    "\n",
    "def get_training():\n",
    "    \"\"\"Returns dataframe data from train.csv \"\"\"\n",
    "    # First, we need to load the data directly into a dataframe from the train.csv file. \n",
    "    df_train = pd.read_csv(TRAIN_PATH)\n",
    "    # Remove all examples with label = 0. (why would i want to train on false examples?)\n",
    "    df_train = df_train.loc[df_train['Label'] == 1.0]\n",
    "    # Don't care about the pandas indices in the df, so remove them.\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_train = df_train[df_train.columns[:2]]\n",
    "    return df_train\n",
    "\n",
    "def get_validation():\n",
    "    \"\"\"Returns data from valid.csv \"\"\"\n",
    "    # First, we need to load the data directly into a dataframe from the train.csv file. \n",
    "    df_valid = pd.read_csv(VALID_PATH)\n",
    "    first_two_cols = df_valid.columns[:2]\n",
    "    df_valid = df_valid[first_two_cols]\n",
    "    df_valid.columns = ['Context', 'Utterance']\n",
    "    return df_valid\n",
    "\n",
    "df_train = get_training()\n",
    "df_valid = get_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Functions for Visualization and Reformatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now get all of the data in a single string and make a 'vocabulary' (unique words). \n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize\n",
    "import pdb\n",
    "\n",
    "def print_single_turn(turn: str):\n",
    "    as_list_of_utters = turn.split('__eou__')[:-1]\n",
    "    for idx_utter, utter in enumerate(as_list_of_utters):\n",
    "        print(\"\\t>>>\", utter)\n",
    "\n",
    "def print_conversation(df, index=0):\n",
    "    \"\"\"Display the ith conversation in nice format.\"\"\"\n",
    "    \n",
    "    # Get the row identified by 'index'. \n",
    "    context_entry = df['Context'].values[index]\n",
    "    target        = df['Utterance'].values[index]\n",
    "    \n",
    "    # Split returns a blank last entry, so don't store.\n",
    "    turns = context_entry.split('__eot__')[:-1]\n",
    "    print('--------------------- CONTEXT ------------------- ')\n",
    "    for idx_turn, turn in enumerate(turns):\n",
    "        print(\"\\nUser {}: \".format(idx_turn % 2))\n",
    "        print_single_turn(turn)\n",
    "    print('\\n--------------------- RESPONSE ------------------- ')\n",
    "    print(\"\\nUser {}: \".format(len(turns) % 2))\n",
    "    print_single_turn(target)\n",
    "        \n",
    "def get_user_arrays(df):\n",
    "    \"\"\"Returns two arrays of every other turn. \n",
    "    Specifically:\n",
    "        len(returned array) is number of rows in df.  I SURE HOPE NOT!\n",
    "        each entry is a numpy array. \n",
    "        each numpy array contains utterances as entries. \n",
    "    \"\"\"\n",
    "    userOne = []\n",
    "    userTwo = []\n",
    "    contexts = df['Context'].values\n",
    "    targets  = df['Utterance'].values\n",
    "    assert(len(contexts) == len(targets))\n",
    "    \n",
    "    for i in range(len(contexts)):\n",
    "        # combined SINGLE CONVERSATION ENTRY of multiple turns each with multiple utterances.\n",
    "        list_of_turns = contexts[i].split('__eot__')[:-1] + [targets[i]]\n",
    "        \n",
    "        # make sure even number of entries\n",
    "        if len(list_of_turns) % 2 != 0:\n",
    "            list_of_turns = list_of_turns[:-1]\n",
    "            \n",
    "        # strip out the __eou__ occurences (leading space bc otherwise would result in two spaces)\n",
    "        list_of_turns = [re.sub(' __eou__', '', t) for t in list_of_turns]\n",
    "        \n",
    "        userOneThisConvo = list_of_turns[0::2]\n",
    "        userTwoThisConvo = list_of_turns[1::2]\n",
    "        \n",
    "        userOne += userOneThisConvo \n",
    "        userTwo += userTwoThisConvo\n",
    "        \n",
    "    assert(len(userOne) == len(userTwo))\n",
    "    return userOne, userTwo\n",
    "\n",
    "def save_to_file(fname, arr):\n",
    "    with open(DATA_DIR+fname,\"w\") as f:\n",
    "        for line in arr:\n",
    "            f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train has 1000000 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think we could import the old comments via r...</td>\n",
       "      <td>basically each xfree86 upload will NOT force u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I 'm not suggesting all - only the ones you mo...</td>\n",
       "      <td>oh ? oops . __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afternoon all __eou__ not entirely related to ...</td>\n",
       "      <td>we 'll have a BOF about this __eou__ so you 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interesting __eou__ grub-install worked with /...</td>\n",
       "      <td>i fully endorse this suggestion &lt; /quimby &gt; __...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and because Python gives Mark a woody __eou__ ...</td>\n",
       "      <td>( i thought someone was going to make a joke a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  i think we could import the old comments via r...   \n",
       "1  I 'm not suggesting all - only the ones you mo...   \n",
       "2  afternoon all __eou__ not entirely related to ...   \n",
       "3  interesting __eou__ grub-install worked with /...   \n",
       "4  and because Python gives Mark a woody __eou__ ...   \n",
       "\n",
       "                                           Utterance  \n",
       "0  basically each xfree86 upload will NOT force u...  \n",
       "1                                oh ? oops . __eou__  \n",
       "2  we 'll have a BOF about this __eou__ so you 'r...  \n",
       "3  i fully endorse this suggestion < /quimby > __...  \n",
       "4  ( i thought someone was going to make a joke a...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"df_train has\", len(df_train), \"rows.\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One: I 'm not suggesting all - only the ones you modify . \n",
      "Two:  ok , it sounds like you 're agreeing with me , then though rather than `` the ones we modify '' , my idea is `` the ones we need to merge '' \n",
      "\n",
      "One: afternoon all not entirely related to warty , but if grub-install takes 5 minutes to install , is this a sign that i should just retry the install : ) \n",
      "Two:  here \n",
      "\n",
      "One:  you might want to know that thinice in warty is buggy compared to that in sid \n",
      "Two:  and apparently GNOME is suddently almost perfect ( out of the thinice problem ) , nobody report bugs : -P I do n't get your question , where do you want to paste ? \n",
      "\n",
      "One:  can i file the panel not linking to eds ? : ) \n",
      "Two:  are you using alt ? or the windows key ? wait for the gnome-themes , component will be added \n",
      "\n",
      "One:  i just restarted X and now nautilus wo n't show the desktop : ( hal is n't starting : ( \n",
      "Two:  do you think we have any interest to have hal support turned on in gnome-vfs at this point ? It increases the sources of problems for no real benefit imho ... \n",
      "\n",
      "One:  is it a known bug that g-s-t does n't know what distribution its running on ? are there any changes to desktop-file-utils you 've got hidden away ? \n",
      "Two:  somebody should really kick that guy *hard* I 've added a build-dep on libxt-dev in warty for zenity \n",
      "\n",
      "One:  arse . xt-dev ? i added libx11-dev so just libxt-dev or libxt and libx11 ? for future note , the xmodmap line in that X sticky-super fixes the problem for me \n",
      "Two:  we have planned to speak about menu organisation during the 2 weeks I need we do n't need to force it ? \n",
      "\n",
      "One:  was away , you said ? nope \n",
      "Two:  the warty repository ok , fine . Thanks nice to get packages update every 30min instead once a day , is n't it : ) \n",
      "\n",
      "One:  you 'll be glad to know i 've fixed my missing arrows in thinice bug \n",
      "Two:  I 've uploaded the gnome-vfs without hal support should be available rsn \n",
      "\n",
      "One:  should g2 in ubuntu do the magic dont-focus-window tricks ? join the gang , get an x-series thinkpad sj has hung on my box , again . what is monday mornings discussion actually about ? \n",
      "Two: we 'll have a BOF about this so you 're coming tomorrow ?\n",
      "\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "oneTest, twoTest = get_user_arrays(df_train.ix[1:2])\n",
    "for one, two in zip(oneTest, twoTest):\n",
    "    print('One:', one)\n",
    "    print('Two:', two)\n",
    "    print()\n",
    "\n",
    "print(len(oneTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- CONTEXT ------------------- \n",
      "\n",
      "User 0: \n",
      "\t>>> interesting \n",
      "\t>>>  grub-install worked with / being ext3 , failed when it was xfs \n",
      "\t>>>  i thought d-i installed the relevant kernel for your machine . i have a p4 and its installed the 386 kernel \n",
      "\t>>>  holy crap a lot of stuff gets installed by default : ) \n",
      "\t>>>  YOU ARE INSTALLING VIM ON A BOX OF MINE \n",
      "\t>>>  ; ) \n",
      "\n",
      "User 1: \n",
      "\t>>>  more like osx than debian ; ) \n",
      "\t>>>  we have a selection of python modules available for great justice ( and python development ) \n",
      "\n",
      "User 0: \n",
      "\t>>>  2.8 is fixing them iirc \n",
      "\n",
      "User 1: \n",
      "\t>>>  pong \n",
      "\t>>>  vino will be in \n",
      "\t>>>  enjoying ubuntu ? \n",
      "\n",
      "User 0: \n",
      "\t>>>  told me to come here \n",
      "\t>>>  suggested thursday as a good day to come \n",
      "\n",
      "User 1: \n",
      "\t>>>  we froze versions a while back : ) \n",
      "\t>>>  you coming today or thursday ? \n",
      "\t>>>  we 're considering shifting it \n",
      "\t>>>  yay \n",
      "\t>>>  enjoying ubuntu ? \n",
      "\t>>>  usplash ! \n",
      "\n",
      "User 0: \n",
      "\t>>>  thats the one \n",
      "\n",
      "User 1: \n",
      "\t>>>  so i saw your email with the mockup at the airport , but it has n't appeared now that i 've pulled my mail : | \n",
      "\n",
      "User 0: \n",
      "\t>>>  i 've got a better one now too , give me a minute \n",
      "\t>>>  we 've got rh9 installed on most desktops . you want me to look at up2date , right ? \n",
      "\n",
      "User 1: \n",
      "\t>>>  aha ! no , the gui thingy \n",
      "\t>>>  it 's more wizardy \n",
      "\t>>>  so the first page is okayish \n",
      "\t>>>  we can do a whole load better on the second page ( icons , translated descriptions ) \n",
      "\t>>>  but that 's the kind of thing i was thinking about \n",
      "\t>>>  ( a single big treeview would get very scary , very quickly ) \n",
      "\t>>>  sure it 's not a hurricane ? \n",
      "\n",
      "User 0: \n",
      "\t>>>  i think experimental is getting 2.8 too \n",
      "\t>>>  let him work on # 1217 : ) \n",
      "\n",
      "User 1: \n",
      "\t>>>  we call it 'universe ' ; ) \n",
      "\t>>>  haha \n",
      "\t>>>  ooh , totally \n",
      "\n",
      "User 0: \n",
      "\t>>>  i want it on in sarge too but nobody else agrees \n",
      "\n",
      "--------------------- RESPONSE ------------------- \n",
      "\n",
      "User 1: \n",
      "\t>>> i fully endorse this suggestion < /quimby > \n",
      "\t>>>  how did your reinstall go ? \n"
     ]
    }
   ],
   "source": [
    "print_conversation(df_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userOne, userTwo = get_user_arrays(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_to_file(\"train_from.txt\", userOne)\n",
    "save_to_file(\"train_to.txt\", userTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_valid has 19560 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Any ideas on how lts will be released ? __eou_...</td>\n",
       "      <td>We are talking 12.04 not 10.04 __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how much hdd use ubuntu default install ? __eo...</td>\n",
       "      <td>thats why i ask how much is default install ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in my country its nearly the 27th __eou__ when...</td>\n",
       "      <td>thanx __eou__</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it 's not out __eou__ __eot__ they probabaly a...</td>\n",
       "      <td>waiting for many things to be setup __eou__ fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are the ext4 drivers stable ? __eou__ __eot__ ...</td>\n",
       "      <td>you sound like it 's updating to skynet . ; ) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  \\\n",
       "0  Any ideas on how lts will be released ? __eou_...   \n",
       "1  how much hdd use ubuntu default install ? __eo...   \n",
       "2  in my country its nearly the 27th __eou__ when...   \n",
       "3  it 's not out __eou__ __eot__ they probabaly a...   \n",
       "4  are the ext4 drivers stable ? __eou__ __eot__ ...   \n",
       "\n",
       "                                           Utterance  \n",
       "0             We are talking 12.04 not 10.04 __eou__  \n",
       "1  thats why i ask how much is default install ? ...  \n",
       "2                                      thanx __eou__  \n",
       "3  waiting for many things to be setup __eou__ fi...  \n",
       "4  you sound like it 's updating to skynet . ; ) ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"df_valid has\", len(df_valid), \"rows.\")\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userOne, userTwo = get_user_arrays(df_valid)\n",
    "save_to_file(\"valid_from.txt\", userOne)\n",
    "save_to_file(\"valid_to.txt\", userTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4028 at 1330067\n",
      "Sentence:\n",
      "  Thanks : ) I know , it uses .deb , but read my words , they say that nothing like .deb or source was there . That is known to me , so Iam thinking of using alien to build the deb I have seen the entire Internet , and even the SDL developers told me , that they do n't exist . lol , what are you saying ? There is no .deb yet for Wesnoth 1.8 , Also , I know I need to compile it , but the source is not available for sdl11-config , I installed them all , no result Yes , the older ones are available . Sorry , but making the previous version are different . The previous versions of Wesnoth did not need all SDL libraries , Lol , thanks , but that is for Wesnoth 1.6.1 , at least 2 years older , But I said 1.8 , anyway . Thanks for the help . I am searching for a source , and let me compile it . Lol , still a formidable game can be made , against Age of Empires series , : D Penumbra if commercial , but O A.D is not , : D A demo is not Open-Source , and also , the what I like is a RTS , like the fans of Age of Mythology and AoK , Also , from the screenthots of O A.D , it appears as if it is a jewel to Ubuntu . The debate continues , if you consider Java too , and I do have them . But , the thing is that , Commercial < Free < Open-Source , so Flash is better than Commercial softwares like Penumbra What we want to advocate Ubuntu for , is freedom and Open-Source . So , commercial games are not welcome here . The best way is to use free and open-source softwares . Is n't our discussion going a bit offtopic ? Also , Non-free softwares are meant for profit , which clashes with the nature of Ubuntu . A mutual profit is always welcome , when it benefits the ideology of the user and the developer . And I have researched nicely enough , but you seem to challenge the nature of Linux , and also , drag the discussion offtopic . In addition , Things like non-free softwares cause a flow of money from the pockets of the users to the developers . But Open-Source is what allows users to be developers . There is , based on User Experience . And Ubuntu is the best . Fame comes from others Individual Judgements , and People accept Ubuntu , since it is the best . Also , Ubuntu is the most user-friendly Linux for PCs . Anything *buntu , whether Lubuntu , Kubuntu or Xubuntu is the best . The talk is related to Open-Source , but Windows is not . Also , many people used Windows , but they are switching to Ubuntu now . And it is Ubuntu who challenged Microsoft in a bold way . Computing World is not only for gaming . For gaming , get a XBox or Playstation . Computer is mainly for learning and development . It is for better use . And in all fields , Ubuntu is the best . For everyday use , Puppy is a joke . Ubuntu and Puppy 's goals differ . Ubuntu JeOS can do the same . Lubuntu is also nicer than Puppy in many ways . In the modern world , People who are in Computing , should upgrade their Systems . And for low-end systems , any Linux with low DE can do . Why only Puppy ? DSL can do the same , and Lubuntu too . The `` best '' is counted as a basis on `` How many fields a thing is better than others '' , and Ubuntu is much better in most cases . So , it is the Best . Check out the Ubuntu Synaptic , and you can get anything like that , low-end system maintainance and so . So , LXDE can be used in Ubuntu , and so can be ICEWM , so Ubuntu can perform much better than Puppy . Also , where is the package manager for Puppy ? Nowhere , Ubuntu has strongest support , because check the supports of both . Nice to know it , but then , community of Ubuntu needs centralization , not fragmentation . I am among Ubuntu Sideline developers too ( the default version ) I know , but is it really nicer than Synaptic ? No , Discussing about Puppy is not welcome here . It is he Ubuntu Support Channel . As per my question 's answers , you seem to start debates on the main support channel . Please do n't do so . Lol , : D it is not so bad , and if you hate google , try www.bing.com , : ) By Microsoft , : ) Lol , nice \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "lengths = np.array([len(t) for t in userOne])\n",
    "\n",
    "max_ind =  lengths.argmax()\n",
    "print(max(lengths), \"at\", max_ind)\n",
    "print(\"Sentence:\\n\", userOne[max_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.87500800e+06,   2.34934000e+05,   3.66330000e+04,\n",
       "          6.93100000e+03,   1.75000000e+03,   5.17000000e+02,\n",
       "          1.48000000e+02,   6.50000000e+01,   3.10000000e+01,\n",
       "          1.70000000e+01]),\n",
       " array([  1.00000000e+00,   1.98100000e+02,   3.95200000e+02,\n",
       "          5.92300000e+02,   7.89400000e+02,   9.86500000e+02,\n",
       "          1.18360000e+03,   1.38070000e+03,   1.57780000e+03,\n",
       "          1.77490000e+03,   1.97200000e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAD8CAYAAACyyUlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw0SS1M0wkSR1M0wkSd3+P5uNoZdCvym1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e44180470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(sorted(lengths)[:-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203512 out of 2156054 (0.09439095681277\\%)\n"
     ]
    }
   ],
   "source": [
    "n_under_20 = sum([1 if l < 20 else 0 for l in lengths])\n",
    "print(n_under_20, \"out of\", len(lengths), \"({}\\%)\".format(float(n_under_20)/len(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
