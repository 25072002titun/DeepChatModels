{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Basics: [DataFrames](https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python#gs.Ulu69Pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"From a numpy array:\", pd.DataFrame(arr), sep=\"\\n\")\n",
    "\n",
    "dic = {1: ['1', '3'], 2: ['1', '2']}\n",
    "print(\"Frum a dictionary:\", pd.DataFrame(dic), sep=\"\\n\")\n",
    "\n",
    "df = pd.DataFrame(data=[4, 5, 6, 7], index=range(0, 4), columns=['A'])\n",
    "print(\"From a df:\", pd.DataFrame(df), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.info(df.drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[1,2,3], [4, 5, 6]]))\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Height:\", len(df.index), end=\"\\n\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define example df:\n",
    "arr = np.arange(1, 10).reshape(3, 3)\n",
    "df = pd.DataFrame(arr, columns=['A', 'B', 'C'])\n",
    "print(\"The examples below all access the top-left '1' in . . . \\n\", df.head(), \"\\n\")\n",
    "\n",
    "# iloc and loc are the 2 main ones.\n",
    "df.iloc[0][0]\n",
    "df.loc[0]['A']\n",
    "v\n",
    "df.at[0, 'A']\n",
    "df.iat[0, 0]\n",
    "df.get_value(0, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Expanding/Removing/Changing Data  from Rows/Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Adding a New Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Append list as column.\n",
    "new_df = df.assign(new_col = pd.Series(np.random.randint(10, size=len(df))).values)\n",
    "# Append column with name 'name'. Values initialized to row index. \n",
    "new_df['name'] = new_df.index\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Changing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check out your DataFrame `df`\n",
    "print(df)\n",
    "\n",
    "# Define the new names of your columns\n",
    "newcols = {\n",
    "    'A': 'new_column_1', \n",
    "    'B': 'new_column_2', \n",
    "    'C': 'new_column_3'\n",
    "}\n",
    "\n",
    "# Use `rename()` to rename your columns\n",
    "df.rename(columns=newcols, inplace=True)\n",
    "\n",
    "# Rename your index\n",
    "df.rename(index={1: 'a'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Replacing String Patterns with Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Check out your DataFrame `df`\n",
    "arr = np.arange(1, 10).reshape(3, 3)\n",
    "arr = [[str(r) for r in row] for row in arr]\n",
    "arr[0][1] += '\\n'\n",
    "arr[1][0] += '\\n'\n",
    "arr[2][2] += '\\n'\n",
    "df = pd.DataFrame(arr)\n",
    "print(\"Before:\\n\", df)\n",
    "\n",
    "df.replace({'\\n': '<br>'}, regex=True, inplace=True)\n",
    "print(\"After:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df)\n",
    "# Replace strings by others with `regex`\n",
    "df.replace({'\\n': '<br>'}, regex=True, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Customizing Display Options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text': ['foo foo foo foo foo foo foo foo', 'bar bar bar bar bar'],\n",
    "                 'number': [1, 2]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.style.set_properties(subset=['text'], **{'width': '800px'})\n",
    "np.info(df.style.set_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "# Saving and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "loss = [0.12, 0.165]\n",
    "learning_rate= [0.5, 0.1]\n",
    "df = pd.DataFrame({\"loss\": loss, \"learning_rate\": learning_rate})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Creating/Appending and Saving DF to File\n",
    "Creates file if exists, else appends to existing one. Useful for repeated updates to data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# When opening to new and/or empty file, do . . . \n",
    "with open('io_test.csv', 'a+') as f:\n",
    "    df.to_csv(f)\n",
    "# When you know the file already exists & isn't empty, do . . . \n",
    "with open('io_test.csv', 'a') as f:\n",
    "    # Don't include header in appended content.\n",
    "    df.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat io_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Loading From CSV Into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_load = pd.read_csv('io_test.csv', index_col=0)\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_load = df_load.append({\"loss\":200, \"learning_rate\":0.01}, ignore_index=True)\n",
    "df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Outputs in EDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import enchant\n",
    "import multiprocessing\n",
    "import sys\n",
    "if os.getcwd() == '/home/brandon/Documents/seq2seq_projects/notebooks':\n",
    "    sys.path.append('..')\n",
    "from data import data_helper\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data import DataHelper\n",
    "from functools import wraps\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from multiprocessing import Pool\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "# Global helper object that helps abstract away locations of\n",
    "# files & directories, and keeps an eye on memory usage.\n",
    "data_helper = DataHelper()\n",
    "# Max number of words in any saved sentence.\n",
    "MAX_SEQ_LEN = 11\n",
    "# Number of CPU cores available.\n",
    "NUM_CORES = 8\n",
    "# How many chunks we should split dataframes into at any given time.\n",
    "NUM_PARTITIONS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def timed_function(*expected_args):\n",
    "    \"\"\"Simple decorator to show how long the functions take to run.\"\"\"\n",
    "    def decorator(fn):\n",
    "        @wraps(fn)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start_time  = time.time()\n",
    "            res         = fn(*args, **kwargs)\n",
    "            stop_time   = time.time()\n",
    "            fname = expected_args[0]\n",
    "            print(\"Time to run %s: %.3f seconds.\" %\n",
    "                  (fname, stop_time - start_time))\n",
    "            return res\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@timed_function('parallel_map_list')\n",
    "def parallel_map_list(fn, iterable):\n",
    "    \"\"\"Based on great explanation from 'Pandas in Parallel' (racketracer.com).\"\"\"\n",
    "    iterable = np.array_split(iterable, NUM_PARTITIONS)\n",
    "    pool = Pool(NUM_CORES)\n",
    "    iterable = np.concatenate(pool.map(fn, iterable))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return iterable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data_helper.safe_load(max_mem=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit API Info\n",
    "[[Source]](www.github.com/reddit/reddit/wiki/JSON)\n",
    "\n",
    "__Base class__\n",
    "\n",
    "name | description \n",
    "----- | :------- \n",
    "id | this item's identifier (not english)\n",
    "name | Fullname of comment (not english)\n",
    "\n",
    "\n",
    "__Comments__: \n",
    "\n",
    "name | description \n",
    "----- | :------- \n",
    "author | account name of the poster (english)\n",
    "body | raw comment text\n",
    "link_id | ID of the link this comment is in\n",
    "parent_id | ID of the thing this comment is a reply to, either the link or a comment in it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_cols = df[['author', 'name', 'link_id', 'parent_id']]\n",
    "id_cols.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi Mitch: check dis error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_dist = nltk.FreqDist(id_cols.name.values)\n",
    "name_dist.most_common()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df.name == 't1_c02afvg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def root_comments(df):\n",
    "    '''Build list determining which rows of df are root comments.\n",
    "\n",
    "    Returns:\n",
    "        list of length equal to the number of rows in our data frame.\n",
    "    '''\n",
    "    root_value = []\n",
    "    # Iterate over DataFrame rows as namedtuples,\n",
    "    # with index value as first element of the tuple.\n",
    "    for row in df.itertuples():\n",
    "        root_value.append(row.parent_id == row.link_id)\n",
    "    return root_value\n",
    "\n",
    "@timed_function('initial_clean')\n",
    "def initial_clean(df):\n",
    "    \"\"\"Throw away columns we don't need and misc. style formatting.\"\"\"\n",
    "    df['root'] = root_comments(df)\n",
    "    # TODO: Can probably remove 'subreddit' column.\n",
    "    df = df[['author', 'body', 'link_id', 'parent_id', 'name', 'root', 'subreddit']]\n",
    "    df.style.set_properties(subset=['body'], **{'width': '500px'})\n",
    "    df.style.set_properties(**{'text-align': 'left'})\n",
    "    df.head()\n",
    "    return df\n",
    "df = initial_clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('len(df.index) =', len(df.index))\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timed_function('regex_replacements')\n",
    "def regex_replacements(df):\n",
    "    # Remove comments that are '[deleted]'.\n",
    "    df = df.loc[df.body != '[deleted]'].reset_index(drop=True)\n",
    "    df.style.set_properties(subset=['body'], **{'width': '800px'})\n",
    "    # Make all comments lowercase to help reduce vocab size.\n",
    "    df['body'] = df['body'].map(lambda s: s.strip().lower())\n",
    "    # Loop over regex replacements specified by modify_list.\n",
    "    for old, new in data_helper.modify_list.items():\n",
    "        df['body'].replace({old: new}, regex=True, inplace=True)\n",
    "    # Remove comments with this extremely common occurrence.\n",
    "    #df = df.loc[df.body != 'NUMBER'].reset_index(drop=True)\n",
    "    return df\n",
    "df = regex_replacements(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('len(df.index) =', len(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Large Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timed_function('remove_large_comments')\n",
    "def remove_large_comments(max_len, df):\n",
    "    # Could probably do a regex find on spaces to make this faster.\n",
    "    df = df[df['body'].map(lambda s: len(s.split())) < max_len].reset_index(drop=True)\n",
    "    df = df[df['body'].map(lambda s: 'http' not in s)].reset_index(drop=True)\n",
    "    return df\n",
    "df = remove_large_comments(max_len=MAX_SEQ_LEN, df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('len(df.index) =', len(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timed_function('expand_contractions')\n",
    "def expand_contractions(df):\n",
    "    \"\"\"Replace all contractions with their expanded form.\"\"\"\n",
    "    for contraction, as_words in data_helper.contractions.items():\n",
    "        df['body'].replace({contraction: as_words}, regex=True, inplace=True)\n",
    "    return df\n",
    "df = expand_contractions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('len(df.index) =', len(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timed_function('children_dict')\n",
    "def children_dict(df):\n",
    "    \"\"\"Returns a dictionary with keys being the root comments and\n",
    "    values being their immediate root_to_children. Assumes that df has 'root' column.\n",
    "\n",
    "    Go through all comments. If it is a root, skip it since they wont have a parent_id\n",
    "    that corresponds to a comment.\n",
    "    \"\"\"\n",
    "    children = {}\n",
    "    for row in df.itertuples():\n",
    "        if row.root == False:\n",
    "            if row.parent_id in children.keys():\n",
    "                children[row.parent_id].append(row.name)\n",
    "            else:\n",
    "                children[row.parent_id] = [row.name]\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = parallel_map_list(fn=DataHelper.word_tokenizer, iterable=df.body.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(chain.from_iterable(sentences))\n",
    "n = 30\n",
    "print(\"Top %d most common words:\" % n)\n",
    "pprint(freq_dist.most_common(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Words that frequently appear together:\")\n",
    "text = nltk.Text(chain.from_iterable(sentences))\n",
    "text.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_helper.set_word_freq(Counter(chain.from_iterable(sentences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_score(sentences):\n",
    "    word_freq = data_helper.word_freq\n",
    "    d = enchant.Dict('en_US')\n",
    "\n",
    "    scores = []\n",
    "    for sentence in sentences:\n",
    "        word_count = len(sentence) + 1e-20\n",
    "        sent_score = sum([1.0 / ((word_freq[w] + 1e-20) * word_count)\n",
    "                      for w in sentence if not d.check(w)])\n",
    "        scores.append(sent_score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['score'] = parallel_map_list(fn=sentence_score, iterable=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand_gen = DataHelper.random_rows_generator(10, len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[next(rand_gen)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries to Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.body.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(df.name.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df.name.values.tolis\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
