{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "%matplotlib inline  \n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter All Directory Info In Cell Below\n",
    "\n",
    "My directory structure (Brandon):\n",
    "```\n",
    "reddit_data\n",
    "    raw_data\n",
    "        2007\n",
    "        ...\n",
    "        2015\n",
    "    processed_data\n",
    "        2007\n",
    "        ...\n",
    "        2015\n",
    "```\n",
    "Only info that needs to be changed to run this notebook is in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently in /home/brandon/Documents/seq2seq_projects/notebooks \n",
      "\n",
      "['/home/brandon/terabyte/Datasets/reddit_data/raw_data/2007/RC_2007-10',\n",
      " '/home/brandon/terabyte/Datasets/reddit_data/raw_data/2007/RC_2007-11',\n",
      " '/home/brandon/terabyte/Datasets/reddit_data/raw_data/2007/RC_2007-12']\n"
     ]
    }
   ],
   "source": [
    "print(\"You are currently in\", os.getcwd(), \"\\n\")\n",
    "DATA_ROOT = '/home/brandon/terabyte/Datasets/reddit_data'\n",
    "DATA_YEAR = '2007'\n",
    "# Use os.path.join; it will figure out the '/' in between.\n",
    "RAW_DATA_FILES = os.listdir(os.path.join(DATA_ROOT, 'raw_data', DATA_YEAR))\n",
    "# Always work with full pathnames to be safe.\n",
    "RAW_DATA_FILES = [os.path.join(DATA_ROOT, 'raw_data', DATA_YEAR, file) for file in RAW_DATA_FILES]\n",
    "pprint(RAW_DATA_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load Data and Display Basic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in raw data file 150429\n",
      "'Column names from raw data file:'\n",
      "Index(['archived', 'author', 'author_flair_css_class', 'author_flair_text',\n",
      "       'body', 'controversiality', 'created_utc', 'distinguished', 'downs',\n",
      "       'edited', 'gilded', 'id', 'link_id', 'name', 'parent_id',\n",
      "       'retrieved_on', 'score', 'score_hidden', 'subreddit', 'subreddit_id',\n",
      "       'ups'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(RAW_DATA_FILES[0], lines=True)\n",
    "init_num_rows = len(df)\n",
    "print(\"Number of lines in raw data file\", init_num_rows)\n",
    "pprint(\"Column names from raw data file:\")\n",
    "pprint(df.columns, width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_len_update(df):\n",
    "    print(\"Now there are\", len(df), \"rows.\")\n",
    "    \n",
    "def root_comments(df):\n",
    "    '''Build list determining which rows of df are root comments.\n",
    "    \n",
    "    Returns: \n",
    "        list of length equal to the number of rows in our data frame. \n",
    "    '''\n",
    "    root_value = []\n",
    "    # Iterate over DataFrame rows as namedtuples, with index value as first element of the tuple.\n",
    "    for row in df.itertuples():\n",
    "        root_value.append(row.parent_id == row.link_id)\n",
    "    return root_value\n",
    "\n",
    "def random_rows_generator(num_rows_per_print, num_rows_total):\n",
    "    num_iterations = num_rows_total // num_rows_per_print \n",
    "    shuffled_indices = np.arange(num_rows_per_print * num_iterations)\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    for batch in shuffled_indices.reshape(num_iterations, num_rows_per_print):\n",
    "        yield batch\n",
    "        \n",
    "#rand_rows = random_rows_generator(4, len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Start by removing comments without a body (deleted).\n",
    "* Remove comments larger than 150 words long.\n",
    "* Remove unneccesary columns. \n",
    "* Add a column determining whether a row is a root comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now there are 150429 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>name</th>\n",
       "      <th>root</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bostich</td>\n",
       "      <td>test</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299an</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>igiveyoumylife</td>\n",
       "      <td>much smoother.\\r\\n\\r\\nIm just glad reddit is back, #reddit in mIRC was entertaining but I had no idea how addicted I had become. Thanks for making the detox somewhat short.</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ao</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arve</td>\n",
       "      <td>Can we please deprecate the word \"Ajax\" now? \\r\\n\\r\\n(But yeah, this _is_ much nicer)</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c02999p</td>\n",
       "      <td>t1_c0299ap</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299aq</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gigaquack</td>\n",
       "      <td>Oh, I see. Fancy schmancy \"submitting....\"</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ah</td>\n",
       "      <td>t1_c0299ar</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  \\\n",
       "0         bostich   \n",
       "1  igiveyoumylife   \n",
       "2            Arve   \n",
       "3       [deleted]   \n",
       "4       gigaquack   \n",
       "\n",
       "                                                                                                                                                                           body  \\\n",
       "0                                                                                                                                                                          test   \n",
       "1  much smoother.\\r\\n\\r\\nIm just glad reddit is back, #reddit in mIRC was entertaining but I had no idea how addicted I had become. Thanks for making the detox somewhat short.   \n",
       "2                                                                                         Can we please deprecate the word \"Ajax\" now? \\r\\n\\r\\n(But yeah, this _is_ much nicer)   \n",
       "3                                                                                                                                                                     [deleted]   \n",
       "4                                                                                                                                    Oh, I see. Fancy schmancy \"submitting....\"   \n",
       "\n",
       "    link_id   parent_id        name   root   subreddit  \n",
       "0  t3_5yba3    t3_5yba3  t1_c0299an   True  reddit.com  \n",
       "1  t3_5yba3    t3_5yba3  t1_c0299ao   True  reddit.com  \n",
       "2  t3_5yba3  t1_c02999p  t1_c0299ap  False  reddit.com  \n",
       "3  t3_5yba3    t3_5yba3  t1_c0299aq   True  reddit.com  \n",
       "4  t3_5yba3  t1_c0299ah  t1_c0299ar  False  reddit.com  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['root'] = root_comments(df)\n",
    "df = df[['author', 'body', 'link_id', 'parent_id', 'name', 'root', 'subreddit']]\n",
    "df.style.set_properties(subset=['body'], **{'width': '500px'})\n",
    "df.style.set_properties(**{'text-align': 'left'})\n",
    "show_len_update(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Unwanted String Patterns in Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update: Hi.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>name</th>\n",
       "      <th>root</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bostich</td>\n",
       "      <td>test</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299an</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>igiveyoumylife</td>\n",
       "      <td>much smoother.  Im just glad reddit is back,  reddit in mIRC was entertaining but I had no idea how addicted I had become. Thanks for making the detox somewhat short.</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ao</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arve</td>\n",
       "      <td>Can we please deprecate the word \"Ajax\" now?   (But yeah, this _is_ much nicer)</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c02999p</td>\n",
       "      <td>t1_c0299ap</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gigaquack</td>\n",
       "      <td>Oh, I see. Fancy schmancy \"submitting....\"</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ah</td>\n",
       "      <td>t1_c0299ar</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Percept</td>\n",
       "      <td>testing ...</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299as</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  \\\n",
       "0         bostich   \n",
       "1  igiveyoumylife   \n",
       "2            Arve   \n",
       "4       gigaquack   \n",
       "5         Percept   \n",
       "\n",
       "                                                                                                                                                                     body  \\\n",
       "0                                                                                                                                                                    test   \n",
       "1  much smoother.  Im just glad reddit is back,  reddit in mIRC was entertaining but I had no idea how addicted I had become. Thanks for making the detox somewhat short.   \n",
       "2                                                                                         Can we please deprecate the word \"Ajax\" now?   (But yeah, this _is_ much nicer)   \n",
       "4                                                                                                                              Oh, I see. Fancy schmancy \"submitting....\"   \n",
       "5                                                                                                                                                             testing ...   \n",
       "\n",
       "    link_id   parent_id        name   root   subreddit  \n",
       "0  t3_5yba3    t3_5yba3  t1_c0299an   True  reddit.com  \n",
       "1  t3_5yba3    t3_5yba3  t1_c0299ao   True  reddit.com  \n",
       "2  t3_5yba3  t1_c02999p  t1_c0299ap  False  reddit.com  \n",
       "4  t3_5yba3  t1_c0299ah  t1_c0299ar  False  reddit.com  \n",
       "5  t3_5yba3    t3_5yba3  t1_c0299as   True  reddit.com  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.style.set_properties(subset=['body'], **{'width': '800px'})\n",
    "df = df.loc[df.body != '[deleted]']\n",
    "remove_list = ['\\r\\n', '\\n', '\\r', '&gt;', '&lt;', # Newlines, >, <, \n",
    "               'https?:\\/\\/(?:www\\.|(?!www))[^\\s\\.]+\\.[^\\s]{2,}|www\\.[^\\s]+\\.[^\\s]{2,}', # URLs\n",
    "              '/__|\\*|\\#|(?:\\[([^\\]]*)\\]\\([^)]*\\))/gm', # Markdown links\n",
    "              ]\n",
    "print(\"Update: Hi.\")\n",
    "for pattern in remove_list:\n",
    "    df['body'].replace({pattern: ' '}, regex=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update: How're you feeling?\n",
      "Update: Because I feel fine.\n",
      "Now there are 126320 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>name</th>\n",
       "      <th>root</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bostich</td>\n",
       "      <td>test</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299an</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>igiveyoumylife</td>\n",
       "      <td>much smoother. im just glad reddit is back, reddit in mirc was entertaining but i had no idea how addicted i had become. thanks for making the detox somewhat short.</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ao</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arve</td>\n",
       "      <td>can we please deprecate the word \"ajax\" now?  (but yeah, this _is_ much nicer)</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c02999p</td>\n",
       "      <td>t1_c0299ap</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gigaquack</td>\n",
       "      <td>oh, i see. fancy schmancy \"submitting. .\"</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ah</td>\n",
       "      <td>t1_c0299ar</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Percept</td>\n",
       "      <td>testing .</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299as</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  \\\n",
       "0         bostich   \n",
       "1  igiveyoumylife   \n",
       "2            Arve   \n",
       "4       gigaquack   \n",
       "5         Percept   \n",
       "\n",
       "                                                                                                                                                                   body  \\\n",
       "0                                                                                                                                                                  test   \n",
       "1  much smoother. im just glad reddit is back, reddit in mirc was entertaining but i had no idea how addicted i had become. thanks for making the detox somewhat short.   \n",
       "2                                                                                        can we please deprecate the word \"ajax\" now?  (but yeah, this _is_ much nicer)   \n",
       "4                                                                                                                             oh, i see. fancy schmancy \"submitting. .\"   \n",
       "5                                                                                                                                                            testing .    \n",
       "\n",
       "    link_id   parent_id        name   root   subreddit  \n",
       "0  t3_5yba3    t3_5yba3  t1_c0299an   True  reddit.com  \n",
       "1  t3_5yba3    t3_5yba3  t1_c0299ao   True  reddit.com  \n",
       "2  t3_5yba3  t1_c02999p  t1_c0299ap  False  reddit.com  \n",
       "4  t3_5yba3  t1_c0299ah  t1_c0299ar  False  reddit.com  \n",
       "5  t3_5yba3    t3_5yba3  t1_c0299as   True  reddit.com  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Misc.\n",
    "print(\"Update: How're you feeling?\")\n",
    "df['body'] = df['body'].map(lambda s: s.strip().lower())\n",
    "df['body'].replace({'  ': ' '}, regex=True, inplace=True)\n",
    "df['body'].replace({'\\[*.\\]\\(*.\\)': ' '}, regex=True, inplace=True) # My simpler Markdown link matcher.\n",
    "print(\"Update: Because I feel fine.\")\n",
    "df['body'].replace({'\\d+': 'NUMBER'}, regex=True, inplace=True)\n",
    "df['body'].replace({'\\[': ''}, regex=True, inplace=True)\n",
    "df['body'].replace({'\\]': ''}, regex=True, inplace=True)\n",
    "df['body'].replace({'\\/\\/': ''}, regex=True, inplace=True)\n",
    "df['body'].replace({'\\.\\.\\.': '. '}, regex=True, inplace=True)\n",
    "#df['body'].replace({'\\s*': ' '}, regex=True, inplace=True)\n",
    "show_len_update(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                                                                                     test\n",
       "1     much smoother. im just glad reddit is back, reddit in mirc was entertaining but i had no idea how addicted i had become. thanks for making the detox somewhat short.\n",
       "2                                                                                           can we please deprecate the word \"ajax\" now?  (but yeah, this _is_ much nicer)\n",
       "4                                                                                                                                oh, i see. fancy schmancy \"submitting. .\"\n",
       "5                                                                                                                                                               testing . \n",
       "6                                                                                                                                               i like it. one more time. \n",
       "7                                                                                                        try refreshing yor cache, that worked for me edit: trying to edit\n",
       "8                                                                                                                                               k. i lied. just one more. \n",
       "9                                                                                                                                 i also wonder what the differences are. \n",
       "10                                                                                                                                                          so addictive. \n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:10]['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remove rows where body is over n words long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before: 126320\n",
      "Now there are 103389 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>name</th>\n",
       "      <th>root</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bostich</td>\n",
       "      <td>test</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299an</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>igiveyoumylife</td>\n",
       "      <td>much smoother. im just glad reddit is back, reddit in mirc was entertaining but i had no idea how addicted i had become. thanks for making the detox somewhat short.</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ao</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arve</td>\n",
       "      <td>can we please deprecate the word \"ajax\" now?  (but yeah, this _is_ much nicer)</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c02999p</td>\n",
       "      <td>t1_c0299ap</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gigaquack</td>\n",
       "      <td>oh, i see. fancy schmancy \"submitting. .\"</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ah</td>\n",
       "      <td>t1_c0299ar</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Percept</td>\n",
       "      <td>testing .</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299as</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  \\\n",
       "0         bostich   \n",
       "1  igiveyoumylife   \n",
       "2            Arve   \n",
       "4       gigaquack   \n",
       "5         Percept   \n",
       "\n",
       "                                                                                                                                                                   body  \\\n",
       "0                                                                                                                                                                  test   \n",
       "1  much smoother. im just glad reddit is back, reddit in mirc was entertaining but i had no idea how addicted i had become. thanks for making the detox somewhat short.   \n",
       "2                                                                                        can we please deprecate the word \"ajax\" now?  (but yeah, this _is_ much nicer)   \n",
       "4                                                                                                                             oh, i see. fancy schmancy \"submitting. .\"   \n",
       "5                                                                                                                                                            testing .    \n",
       "\n",
       "    link_id   parent_id        name   root   subreddit  \n",
       "0  t3_5yba3    t3_5yba3  t1_c0299an   True  reddit.com  \n",
       "1  t3_5yba3    t3_5yba3  t1_c0299ao   True  reddit.com  \n",
       "2  t3_5yba3  t1_c02999p  t1_c0299ap  False  reddit.com  \n",
       "4  t3_5yba3  t1_c0299ah  t1_c0299ar  False  reddit.com  \n",
       "5  t3_5yba3    t3_5yba3  t1_c0299as   True  reddit.com  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 60\n",
    "print(\"Length before:\", df['body'].size)\n",
    "df = df[df['body'].map(lambda s: len(s.split(' '))) < n]\n",
    "show_len_update(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows where body == 'NUMBER'. There are a lot. Hacky but w/e. Wow it worked. heh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now there are 102966 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>name</th>\n",
       "      <th>root</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bostich</td>\n",
       "      <td>test</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299an</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>igiveyoumylife</td>\n",
       "      <td>much smoother. im just glad reddit is back, reddit in mirc was entertaining but i had no idea how addicted i had become. thanks for making the detox somewhat short.</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ao</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arve</td>\n",
       "      <td>can we please deprecate the word \"ajax\" now?  but yeah, this _is_ much nicer</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c02999p</td>\n",
       "      <td>t1_c0299ap</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gigaquack</td>\n",
       "      <td>oh, i see. fancy schmancy \"submitting. .\"</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299ah</td>\n",
       "      <td>t1_c0299ar</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Percept</td>\n",
       "      <td>testing .</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t3_5yba3</td>\n",
       "      <td>t1_c0299as</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  \\\n",
       "0         bostich   \n",
       "1  igiveyoumylife   \n",
       "2            Arve   \n",
       "4       gigaquack   \n",
       "5         Percept   \n",
       "\n",
       "                                                                                                                                                                   body  \\\n",
       "0                                                                                                                                                                  test   \n",
       "1  much smoother. im just glad reddit is back, reddit in mirc was entertaining but i had no idea how addicted i had become. thanks for making the detox somewhat short.   \n",
       "2                                                                                          can we please deprecate the word \"ajax\" now?  but yeah, this _is_ much nicer   \n",
       "4                                                                                                                             oh, i see. fancy schmancy \"submitting. .\"   \n",
       "5                                                                                                                                                            testing .    \n",
       "\n",
       "    link_id   parent_id        name   root   subreddit  \n",
       "0  t3_5yba3    t3_5yba3  t1_c0299an   True  reddit.com  \n",
       "1  t3_5yba3    t3_5yba3  t1_c0299ao   True  reddit.com  \n",
       "2  t3_5yba3  t1_c02999p  t1_c0299ap  False  reddit.com  \n",
       "4  t3_5yba3  t1_c0299ah  t1_c0299ar  False  reddit.com  \n",
       "5  t3_5yba3    t3_5yba3  t1_c0299as   True  reddit.com  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body'].replace({'NUMBER': ' '}, regex=True, inplace=True)\n",
    "df['body'].replace({'^.*NUMBER.*NUMBER.*$': ''}, regex=True, inplace=True)\n",
    "df['body'].replace({'\\[|\\]|\\(|\\)': ''}, regex=True, inplace=True)\n",
    "df['body'].replace({'\\'': ''}, regex=True, inplace=True)\n",
    "df['body'].replace({'-*': ''}, regex=True, inplace=True)\n",
    "df['body'].replace({'\\$|%': ''}, regex=True, inplace=True)\n",
    "df = df[df['body'].map(lambda s: s == '') == False]\n",
    "show_len_update(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>name</th>\n",
       "      <th>root</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150421</th>\n",
       "      <td>folderol</td>\n",
       "      <td>muscle memory.  or he never knew how to run and hence took up race walking.</td>\n",
       "      <td>t3_5zj73</td>\n",
       "      <td>t1_c02cfl4</td>\n",
       "      <td>t1_c02cheo</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150422</th>\n",
       "      <td>michaelco</td>\n",
       "      <td>man develops delusions wow thats a headline</td>\n",
       "      <td>t3_5zjx2</td>\n",
       "      <td>t3_5zjx2</td>\n",
       "      <td>t1_c02chep</td>\n",
       "      <td>True</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150424</th>\n",
       "      <td>aletoledo</td>\n",
       "      <td>i have a list of redditers i wish to have censored. when weve reached that point i think we can then call it enough. so screw everyone getting free speech, we need to get an even balance between profit and freedom.</td>\n",
       "      <td>t3_5zk1h</td>\n",
       "      <td>t1_c02che2</td>\n",
       "      <td>t1_c02cher</td>\n",
       "      <td>False</td>\n",
       "      <td>reddit.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150425</th>\n",
       "      <td>Dark-Star</td>\n",
       "      <td>nope. too lazy and dont care for until they or a close friend are touched by the drug war disaster. . and the ones who do rise will promptly be jailed or shot. some may rise nonetheless, but it sure as hell wont end much except their freedom.</td>\n",
       "      <td>t3_5zimk</td>\n",
       "      <td>t1_c02cebw</td>\n",
       "      <td>t1_c02ches</td>\n",
       "      <td>False</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150427</th>\n",
       "      <td>M0b1u5</td>\n",
       "      <td>us: we are fucking idiots.</td>\n",
       "      <td>t3_5zep2</td>\n",
       "      <td>t3_5zep2</td>\n",
       "      <td>t1_c02cheu</td>\n",
       "      <td>True</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author  \\\n",
       "150421   folderol   \n",
       "150422  michaelco   \n",
       "150424  aletoledo   \n",
       "150425  Dark-Star   \n",
       "150427     M0b1u5   \n",
       "\n",
       "                                                                                                                                                                                                                                                      body  \\\n",
       "150421                                                                                                                                                                         muscle memory.  or he never knew how to run and hence took up race walking.   \n",
       "150422                                                                                                                                                                                                         man develops delusions wow thats a headline   \n",
       "150424                              i have a list of redditers i wish to have censored. when weve reached that point i think we can then call it enough. so screw everyone getting free speech, we need to get an even balance between profit and freedom.   \n",
       "150425  nope. too lazy and dont care for until they or a close friend are touched by the drug war disaster. . and the ones who do rise will promptly be jailed or shot. some may rise nonetheless, but it sure as hell wont end much except their freedom.   \n",
       "150427                                                                                                                                                                                                                          us: we are fucking idiots.   \n",
       "\n",
       "         link_id   parent_id        name   root   subreddit  \n",
       "150421  t3_5zj73  t1_c02cfl4  t1_c02cheo  False  reddit.com  \n",
       "150422  t3_5zjx2    t3_5zjx2  t1_c02chep   True  reddit.com  \n",
       "150424  t3_5zk1h  t1_c02che2  t1_c02cher  False  reddit.com  \n",
       "150425  t3_5zimk  t1_c02cebw  t1_c02ches  False    politics  \n",
       "150427  t3_5zep2    t3_5zep2  t1_c02cheu   True    politics  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117829</th>\n",
       "      <td>\"goedel\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117830</th>\n",
       "      <td>needz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117831</th>\n",
       "      <td>luxembourg.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117832</th>\n",
       "      <td>squeak/morphic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117833</th>\n",
       "      <td>frisky</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Word  Frequency\n",
       "117829        \"goedel\"          1\n",
       "117830           needz          1\n",
       "117831     luxembourg.          1\n",
       "117832  squeak/morphic          1\n",
       "117833          frisky          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: http://stackoverflow.com/questions/38557617/how-to-get-all-the-unique-words-in-the-data-frame\n",
    "word_freqs = df['body'].str.split(' ', expand=True).stack().value_counts()\n",
    "word_freqs = pd.DataFrame(list(word_freqs.items()), columns=['Word', 'Frequency'])\n",
    "word_freqs.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words (ish): 117834.0\n"
     ]
    }
   ],
   "source": [
    "# \"COUNT\" is number of unique words. Useful!\n",
    "des = word_freqs['Frequency'].describe()\n",
    "vocab_size = des['count']\n",
    "print(\"number of unique words (ish):\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 40\n",
    "start=-n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 most common words:\n",
      "     Word  Frequency\n",
      "0     the      86874\n",
      "1              54751\n",
      "2      to      51473\n",
      "3       a      48138\n",
      "4       i      38681\n",
      "5      of      37230\n",
      "6     and      34489\n",
      "7      is      32706\n",
      "8    that      28626\n",
      "9     you      27570\n",
      "10     in      25092\n",
      "11     it      22712\n",
      "12    for      19464\n",
      "13   this      14518\n",
      "14    not      14113\n",
      "15    are      13911\n",
      "16     be      13455\n",
      "17     on      13355\n",
      "18   have      12536\n",
      "19   with      11582\n",
      "20    but      11445\n",
      "21   they      11425\n",
      "22    its      10937\n",
      "23    was      10367\n",
      "24     if      10291\n",
      "25     as       9951\n",
      "26   just       8886\n",
      "27   what       8520\n",
      "28   like       8463\n",
      "29     or       8383\n",
      "30   your       8102\n",
      "31     my       7674\n",
      "32  about       7444\n",
      "33   dont       7314\n",
      "34     so       7172\n",
      "35     at       7114\n",
      "36    all       7070\n",
      "37  would       7058\n",
      "38     do       7012\n",
      "39     an       6891\n"
     ]
    }
   ],
   "source": [
    "start += n\n",
    "print(\"%d most common words:\" % n)\n",
    "print(word_freqs[start:start+n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "30 least common words:\n",
      "                  Word  Frequency\n",
      "117804       unpatched          1\n",
      "117805    inadvertent,          1\n",
      "117806        muppets.          1\n",
      "117807      squeamish.          1\n",
      "117808      maggotesse          1\n",
      "117809      bojangles,          1\n",
      "117810             mr?          1\n",
      "117811             ml!          1\n",
      "117812            pig:          1\n",
      "117813             ien          1\n",
      "117814         loaned.          1\n",
      "117815      sheogorath          1\n",
      "117816       \"dramatic          1\n",
      "117817          ricky,          1\n",
      "117818       mohammad.          1\n",
      "117819      chapparal.          1\n",
      "117820          maine!          1\n",
      "117821       science\",          1\n",
      "117822           nids,          1\n",
      "117823  concealedcarry          1\n",
      "117824            \"rat          1\n",
      "117825       procuring          1\n",
      "117826          rushed          1\n",
      "117827          birds\"          1\n",
      "117828           cant:          1\n",
      "117829        \"goedel\"          1\n",
      "117830           needz          1\n",
      "117831     luxembourg.          1\n",
      "117832  squeak/morphic          1\n",
      "117833          frisky          1\n",
      "Number of unique\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "print(\"\\n%d least common words:\" % n)\n",
    "print(word_freqs[-n:])\n",
    "print(\"Number of unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Returns a dictionary with keys being the root comments and values being their immediate children.\n",
    "## Assumes to have a 'root' column already\n",
    "\n",
    "## Go through all comments, if it is a root skip it since they wont have a parent_id corresponding\n",
    "## to a comment.\n",
    "## \n",
    "def children_dict(df):\n",
    "    children = {}\n",
    "    for row in df.itertuples():\n",
    "        if row.root == False:\n",
    "            if row.parent_id in children.keys():\n",
    "                children[row.parent_id].append(row.name)\n",
    "            else:\n",
    "                children[row.parent_id] = [row.name]\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Return a dictionary with name being the key and body being the value. \n",
    "values_dict = pd.Series(df.body.values, index=df.name).to_dict()\n",
    "children = children_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Generates two files, [from_file_path] and [to_file_path] of one-to-one comments. \n",
    "def generate_files(from_file_path, to_file_path):\n",
    "    ## Open the files and clear them. \n",
    "    from_file = open(from_file_path, 'w')\n",
    "    to_file = open(to_file_path, 'w')\n",
    "    from_file.write(\"\")\n",
    "    to_file.write(\"\")\n",
    "    from_file.close()\n",
    "    to_file.close()\n",
    "\n",
    "    for key in children.keys():\n",
    "        from_file = open(from_file_path, 'a')\n",
    "        to_file = open(to_file_path, 'a')\n",
    "\n",
    "        ## Since we have deleted comments, some comments parents might not exist anymore so we must catch that error.\n",
    "        for child in children[key]:\n",
    "            try: \n",
    "                from_file.write(values_dict[key].replace('\\n', '').replace('\\r', ' ').replace('&gt', '') + \"\\n\")\n",
    "                to_file.write(values_dict[child].replace('\\n', '').replace('\\r', ' ').replace('&gt', '') + \"\\n\")\n",
    "            except KeyError:    \n",
    "                pass\n",
    "    from_file.close()\n",
    "    to_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_into_n.sh\t\t train_to.txt.ids65536\t  valid_to.txt.ids65536\r\n",
      "train_from.txt\t\t valid_from.txt\t\t  vocab40000.from\r\n",
      "train_from.txt.ids40000  valid_from.txt.ids40000  vocab40000.to\r\n",
      "train_from.txt.ids65536  valid_from.txt.ids65536  vocab65536.from\r\n",
      "train_to.txt\t\t valid_to.txt\t\t  vocab65536.to\r\n",
      "train_to.txt.ids40000\t valid_to.txt.ids40000\r\n"
     ]
    }
   ],
   "source": [
    "dat_boi = os.path.join(DATA_ROOT, 'processed_data', DATA_YEAR)\n",
    "!ls $dat_boi\n",
    "!rm $dat_boi/*ids* $dat_boi/*vocab* $dat_boi/*.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k done\n"
     ]
    }
   ],
   "source": [
    "train_from_path = os.path.join(DATA_ROOT, 'processed_data', DATA_YEAR, 'train_from.txt')\n",
    "train_to_path = os.path.join(DATA_ROOT, 'processed_data', DATA_YEAR, 'train_to.txt')\n",
    "generate_files(train_from_path, train_to_path)\n",
    "print('k done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BASH It Up!\n",
    "\n",
    "Haha. We *are* having a blast, aren't we? Let's split those silly files into some training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd \"${DATA_ROOT}/processed_data/DATA_YEAR\"\n",
    "echo \"that doesn't work in jupyter you crazy guy! but lets keep going anyway!\"\n",
    "n=$1\n",
    "cp train_from.txt train_from_full.txt\n",
    "head -n -\"$n\" \"train_from_full.txt\" >> \"train_from.txt\"\n",
    "tail -n \"$n\" \"train_from_full.txt\" >> \"valid_from.txt\"\n",
    "\n",
    "cp train_to.txt train_to_full.txt\n",
    "head -n -\"$n\" \"train_to_full.txt\" >> \"train_to.txt\"\n",
    "tail -n \"$n\" \"train_to_full.txt\" >> \"valid_to.txt\"\n",
    "\n",
    "rm *_full.txt\n",
    "wc -l *\n",
    "\n",
    "cd - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "f = open(train_from_path, 'r')\n",
    "raw_text = f.read()\n",
    "tokens = nltk.word_tokenize(raw_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168277"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## take a list of tokens and convert it into a dictionary whose keys are the words and values are the word count\n",
    "def create_word_dictionary(tokens):\n",
    "    word_dictionary = {}\n",
    "    for word in tokens:\n",
    "        if word in word_dictionary.keys():\n",
    "            word_dictionary[word] += 1\n",
    "        else: \n",
    "            word_dictionary[word] = 1\n",
    "    return word_dictionary\n",
    "\n",
    "def clean_word_dictinoary(word_dict):\n",
    "    return {key: value for key, value in word_dict.items()\n",
    "            if value < 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = create_word_dictionary(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = dictionary.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "values = list(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.616770462633454"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_dict = clean_word_dictinoary(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35301"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A histogram of frequency of word occurence for words which occur less than 300 times in our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94b21e6cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(clean_dict.values()), bins = 100)\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'can you please explain what materialism and atheism did to tibet, china or cambodia?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = nltk.sent_tokenize(raw_text)\n",
    "lens = [len(s.split(' ')) for s in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.64787000e+05,   3.39600000e+03,   7.00000000e+01,\n",
       "          1.20000000e+01,   8.00000000e+00,   2.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.00000000e+00]),\n",
       " array([   1. ,   33.3,   65.6,   97.9,  130.2,  162.5,  194.8,  227.1,\n",
       "         259.4,  291.7,  324. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f94b2346c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Removing Links\n",
    "1. The format for links is \"[link description] (link.link)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contains_link(dictionary):\n",
    "    \"\"\" Determines if the comment contains a link.\n",
    "    Returns a list of Booleans indicating this.\n",
    "    \"\"\"\n",
    "    return {key: value for key, value in dictionary.items() \n",
    "           if fnmatch.fnmatch(value, \"*[ * ]*\") }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = \"This is a test[at](ata)\"\n",
    "import re\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_dict = contains_link(values_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
