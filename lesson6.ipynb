{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from imp import reload\n",
    "import utils; reload(utils)\n",
    "import dl_course_utils; reload(dl_course_utils)\n",
    "from dl_course_utils import *\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup [25:00]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to download the collected works of Nietzsche to use as our data for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))\n",
    "unique_chars = sorted(list(set(text)))\n",
    "vocab_size = len(unique_chars) + 1\n",
    "print('total chars:', vocab_size)\n",
    "# Sometimes it's useful to have a zero value in the dataset, e.g. for padding\n",
    "# Inserts \"\\0\" before index 0 in unique_chars (in-place). \n",
    "unique_chars.insert(0, \"\\0\")\n",
    "''.join(unique_chars[1:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(unique_chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(unique_chars))\n",
    "# idx will be data we use from now on. \n",
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "def get_char_list(idx, offset, step):\n",
    "    start, stop = 0, (len(idx) - step - 1)\n",
    "    return [idx[i + offset] for i in range(start, stop, step)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 3 char model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "REMOVED ILLUSTRATION BECAUSE IT IS TERRIBLE\n",
    "* Pick a size for our hidden state. \n",
    "* Our first hidden activation is simply this function applied to the result of the embedding of the first character.\n",
    "* `dense_hidden` is the 'orange arrow' from our diagram - the layer operation from hidden to hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "seq_len = 3\n",
    "X_train = [np.stack(get_char_list(idx, offset=offset, step=seq_len)[:-2]) for offset in range(seq_len)]\n",
    "y_train = np.stack(get_char_list(idx, offset=seq_len, step=seq_len)[:-2])\n",
    "\n",
    "X_train[0][:4]\n",
    "X_train[0].shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charRNN = MyRNN(vocab_size=vocab_size, \n",
    "                dicts=[char_indices, indices_char],\n",
    "                seq_len=seq_len, \n",
    "                n_hid=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charRNN.fit(X_train, \n",
    "            y_train,\n",
    "            batch_size=64, \n",
    "            nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "charRNN.model.optimizer.lr = 1e-2\n",
    "charRNN.fit(X_train, y_train, batch_size=64, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Prediction for \\\"phi\\\":\", charRNN.predict('phi', unique_chars))\n",
    "print(\"Prediction for \\\" th\\\":\", charRNN.predict(' th', unique_chars))\n",
    "print(\"Prediction for \\\" an\\\":\", charRNN.predict(' an', unique_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len = 8\n",
    "\n",
    "X_train = [np.stack(get_char_list(idx, offset=offset, step=seq_len)[:-2]) for offset in range(seq_len)]\n",
    "y_train = np.stack(get_char_list(idx, offset=seq_len, step=seq_len)[:-2])\n",
    "\n",
    "simpleRNN = MyRNN(vocab_size=vocab_size, \n",
    "                  model_type='SimpleRNN',\n",
    "                  dicts=[char_indices, indices_char], \n",
    "                  seq_len=seq_len, \n",
    "                  n_hid=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simpleRNN.fit(np.stack(X_train, 1), y_train, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction for \\\"this is \\\":\", simpleRNN.predict('  this i', unique_chars))\n",
    "print(\"Prediction for \\\"part of \\\":\", simpleRNN.predict('  part o', unique_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Returning sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a sequence model, we can leave our input unchanged - but we have to change our output to a sequence (of course!)\n",
    "\n",
    "Here, c_out_dat is identical to c_in_dat, but moved across 1 character. Reading down each column shows one set of inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len = 8\n",
    "X_train = [np.stack(get_char_list(idx, offset=offset, step=seq_len)[:-2]) for offset in range(seq_len)]\n",
    "y_train = [np.stack([idx[i+n] for i in range(1, len(idx) - seq_len, seq_len)][:-2]) for n in range(seq_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqRNN = MyRNN(vocab_size=vocab_size, \n",
    "              model_type='SeqRNN',\n",
    "              dicts=[char_indices, indices_char], \n",
    "              seq_len=8, \n",
    "              n_hid=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seqRNN.fit(X_train, y_train, batch_size=64, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction for \\\"this is \\\":\", seqRNN.predict(' this is', unique_chars))\n",
    "print(\"Prediction for \\\"part of \\\":\", seqRNN.predict(' part of', unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction for \\\"for thos\\\":\", seqRNN.predict('for thos', unique_chars))\n",
    "print(\"Prediction for \\\"part of \\\":\", seqRNN.predict('part of ', unique_chars))\n",
    "print(\"Prediction for \\\"queens a\\\":\", seqRNN.predict('queens a', unique_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sequence model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_hidden, n_fac, cs = 256, 42, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our previous keras model into a sequence model, simply add the 'return_sequences=True' parameter, and add TimeDistributed() around our dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xs = X_train\n",
    "ys = y_train\n",
    "print(\"(n_hidden, n_fac, cs, vocab_size)=({}, {}, {}, {})\".format(*(n_hidden, n_fac, cs, vocab_size)))\n",
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs),\n",
    "        SimpleRNN(n_hidden, return_sequences=True, activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())\n",
    "print(\"xs[0].shape=\", xs[0].shape)\n",
    "\n",
    "\n",
    "x_rnn=np.stack(xs, 1)\n",
    "#y_rnn=np.expand_dims(np.stack(ys[:, None], axis=1), -1)\n",
    "y_rnn=np.stack(ys)\n",
    "y_rnn=y_rnn.reshape(y_rnn.shape[1], y_rnn.shape[0], 1)\n",
    "print(x_rnn.shape, y_rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_rnn, y_rnn, batch_size=64, nb_epoch=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_indices[c] for c in inp]\n",
    "    arr = np.array(idxs)[np.newaxis,:]\n",
    "    #arr = [np.array(i)[np.newaxis,:] for i in idxs]\n",
    "    p = model.predict(arr)[0]\n",
    "    return [unique_chars[o.argmax()] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_nexts_keras(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### One-hot sequence model with keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the keras version of the theano model that we're about to create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        SimpleRNN(n_hidden, return_sequences=True, input_shape=(cs, vocab_size),\n",
    "                  activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oh_ys = [to_categorical(o, vocab_size) for o in ys]\n",
    "oh_y_rnn=np.stack(oh_ys, axis=1)\n",
    "\n",
    "oh_xs = [to_categorical(o, vocab_size) for o in xs]\n",
    "oh_x_rnn=np.stack(oh_xs, axis=1)\n",
    "\n",
    "oh_x_rnn.shape, oh_y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nexts_oh(inp):\n",
    "    idxs = np.array([char_indices[c] for c in inp])\n",
    "    arr = to_categorical(idxs, vocab_size)\n",
    "    p = model.predict(arr[np.newaxis,:])[0]\n",
    "    print(list(inp))\n",
    "    return [unique_chars[np.argmax(o)] for o in p]\n",
    "\n",
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stateful model with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A stateful model is easy to create (just add \"stateful=True\") but harder to train. We had to add batchnorm and use LSTM to get reasonable results.\n",
    "\n",
    "When using stateful in keras, you have to also add 'batch_input_shape' to the first layer, and fix the batch size there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=cs, batch_input_shape=(bs,8)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, return_sequences=True, stateful=True),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're using a fixed batch shape, we have to ensure our inputs and outputs are a even multiple of the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mx = len(x_rnn)//bs*bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, nb_epoch=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(x_rnn[:mx], y_rnn[:mx], batch_size=bs, nb_epoch=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using raw theano, we have to create our weight matrices and bias vectors ourselves - here are the functions we'll use to do so (using glorot initialization).\n",
    "\n",
    "The return values are wrapped in `shared()`, which is how we tell theano that it can manage this data (copying it to and from the GPU as necessary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_wgts(rows, cols): \n",
    "    scale = math.sqrt(2/rows)\n",
    "    return shared(normal(scale=scale, size=(rows, cols)).astype(np.float32))\n",
    "def init_bias(rows): \n",
    "    return shared(np.zeros(rows, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We return the weights and biases together as a tuple. For the hidden weights, we'll use an identity initialization (as recommended by [Hinton](https://arxiv.org/abs/1504.00941).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wgts_and_bias(n_in, n_out): \n",
    "    return init_wgts(n_in, n_out), init_bias(n_out)\n",
    "def id_and_bias(n): \n",
    "    return shared(np.eye(n, dtype=np.float32)), init_bias(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano doesn't actually do any computations until we explicitly compile and evaluate the function (at which point it'll be turned into CUDA code and sent off to the GPU). So our job is to describe the computations that we'll want theano to do - the first step is to tell theano what inputs we'll be providing to our computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_inp = T.matrix('inp')\n",
    "t_outp = T.matrix('outp')\n",
    "t_h0 = T.vector('h0')\n",
    "lr = T.scalar('lr')\n",
    "\n",
    "all_args = [t_h0, t_inp, t_outp, lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create our intial weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = wgts_and_bias(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W_h, W_x, W_y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theano handles looping by using the [GPU scan](http://http.developer.nvidia.com/GPUGems3/gpugems3_ch39.html) operation. We have to tell theano what to do at each step through the scan - this is the function we'll use, which does a single forward pass for one character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_x, b_x, W_y, b_y):\n",
    "    # Calculate the hidden activations\n",
    "    h = nnet.relu(T.dot(x, W_x) + b_x + T.dot(h, W_h) + b_h)\n",
    "    # Calculate the output activations\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    # Return both (the 'Flatten()' is to work around a theano bug)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can provide everything necessary for the scan operation, so we can setup that up - we have to pass in the function to call at each step, the sequence to step through, the initial values of the outputs, and any other arguments to pass to the step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate our loss function, and *all* of our gradients, with just a couple of lines of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We even have to show theano how to do SGD - so we set up this dictionary of updates to complete after every forward pass, which apply to standard SGD update rule to every weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})\n",
    "\n",
    "upd = upd_dict(w_all, g_all, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're finally ready to compile the function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = oh_x_rnn\n",
    "Y = oh_y_rnn\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use it, we simply loop through our input data, calling the function compiled above, and printing our progress from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "err=0.0; l_rate=0.01\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        print (\"Error:{:.3f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_y = theano.function([t_h0, t_inp], v_y, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = np.argmax(f_y(np.zeros(n_hidden), X[6]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "act = np.argmax(X[6], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[indices_char[o] for o in act]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[indices_char[o] for o in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure python RNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Set up basic functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we're going to try to repeat the above theano RNN, using just pure python (and numpy). Which means, we have to do everything ourselves, including defining the basic functions of a neural net! Below are all of the definitions, along with tests to check that they give the same answers as theano. The functions ending in `_d` are the derivatives of each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+np.exp(-x))\n",
    "def sigmoid_d(x): \n",
    "    output = sigmoid(x)\n",
    "    return output*(1-output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def relu(x): return np.maximum(0., x)\n",
    "def relu_d(x): return (x > 0.)*1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "relu(np.array([3.,-3.])), relu_d(np.array([3.,-3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dist(a,b): return pow(a-b,2)\n",
    "def dist_d(a,b): return 2*(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-7\n",
    "def x_entropy(pred, actual): \n",
    "    return -np.sum(actual * np.log(np.clip(pred, eps, 1-eps)))\n",
    "def x_entropy_d(pred, actual): return -actual/pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax(x): return np.exp(x)/np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax_d(x):\n",
    "    sm = softmax(x)\n",
    "    res = np.expand_dims(-sm,-1)*sm\n",
    "    res[np.diag_indices_from(res)] = sm*(1-sm)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_preds = np.array([0.2,0.7,0.1])\n",
    "test_actuals = np.array([0.,1.,0.])\n",
    "nnet.categorical_crossentropy(test_preds, test_actuals).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_entropy(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_inp = T.dvector()\n",
    "test_out = nnet.categorical_crossentropy(test_inp, test_actuals)\n",
    "test_grad = theano.function([test_inp], T.grad(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_entropy_d(test_preds, test_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pre_pred = random(oh_x_rnn[0][0].shape)\n",
    "preds = softmax(pre_pred)\n",
    "actual = oh_x_rnn[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.allclose(softmax_d(pre_pred).dot(loss_d(preds,actual)), preds-actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "softmax(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nnet.softmax(test_preds).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_out = T.flatten(nnet.softmax(test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad = theano.function([test_inp], theano.gradient.jacobian(test_out, test_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_grad(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "softmax_d(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "act=relu\n",
    "act_d = relu_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss=x_entropy\n",
    "loss_d=x_entropy_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We also have to define our own scan function. Since we're not worrying about running things in parallel, it's very simple to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def scan(fn, start, seq):\n",
    "    res = []\n",
    "    prev = start\n",
    "    for s in seq:\n",
    "        app = fn(prev, s)\n",
    "        res.append(app)\n",
    "        prev = app\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...for instance, `scan` on `+` is the cumulative sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "scan(lambda prev,curr: prev+curr, 0, range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build the functions to do the forward and backward passes of our RNN. First, define our data and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = oh_x_rnn\n",
    "outp = oh_y_rnn\n",
    "n_input = vocab_size\n",
    "n_output = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp.shape, outp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the function to do a single forward pass of an RNN, for a single character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_char(prev, item):\n",
    "    # Previous state\n",
    "    tot_loss, pre_hidden, pre_pred, hidden, ypred = prev\n",
    "    # Current inputs and output\n",
    "    x, y = item\n",
    "    pre_hidden = np.dot(x,w_x) + np.dot(hidden,w_h)\n",
    "    hidden = act(pre_hidden)\n",
    "    pre_pred = np.dot(hidden,w_y)\n",
    "    ypred = softmax(pre_pred)\n",
    "    return (\n",
    "        # Keep track of loss so we can report it\n",
    "        tot_loss+loss(ypred, y),\n",
    "        # Used in backprop\n",
    "        pre_hidden, pre_pred, \n",
    "        # Used in next iteration\n",
    "        hidden, \n",
    "        # To provide predictions\n",
    "        ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `scan` to apply the above to a whole sequence of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_chars(n): return zip(inp[n], outp[n])\n",
    "def one_fwd(n): return scan(one_char, (0,0,0,np.zeros(n_hidden),0), get_chars(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the backward step. We use a loop to go through every element of the sequence. The derivatives are applying the chain rule to each step, and accumulating the gradients across the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"Columnify\" a vector\n",
    "def col(x): return x[:,newaxis]\n",
    "\n",
    "def one_bkwd(args, n):\n",
    "    global w_x,w_y,w_h\n",
    "\n",
    "    i=inp[n]  # 8x86\n",
    "    o=outp[n] # 8x86\n",
    "    d_pre_hidden = np.zeros(n_hidden) # 256\n",
    "    for p in reversed(range(len(i))):\n",
    "        totloss, pre_hidden, pre_pred, hidden, ypred = args[p]\n",
    "        x=i[p] # 86\n",
    "        y=o[p] # 86\n",
    "        d_pre_pred = softmax_d(pre_pred).dot(loss_d(ypred,y))  # 86\n",
    "        d_pre_hidden = (np.dot(d_pre_hidden, w_h.T) \n",
    "                        + np.dot(d_pre_pred,w_y.T)) * act_d(pre_hidden) # 256\n",
    "\n",
    "        # d(loss)/d(w_y) = d(loss)/d(pre_pred) * d(pre_pred)/d(w_y)\n",
    "        w_y -= col(hidden) * d_pre_pred * alpha\n",
    "        # d(loss)/d(w_h) = d(loss)/d(pre_hidden[p-1]) * d(pre_hidden[p-1])/d(w_h)\n",
    "        if (p>0): w_h -= args[p-1][3].dot(d_pre_hidden) * alpha\n",
    "        w_x -= col(x)*d_pre_hidden * alpha\n",
    "    return d_pre_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up our initial weight matrices. Note that we're not using bias at all in this example, in order to keep things simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scale=math.sqrt(2./n_input)\n",
    "w_x = normal(scale=scale, size=(n_input,n_hidden))\n",
    "w_y = normal(scale=scale, size=(n_hidden, n_output))\n",
    "w_h = np.eye(n_hidden, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loop looks much like the theano loop in the previous section, except that we have to call the backwards step ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overallError=0\n",
    "alpha=0.0001\n",
    "for n in range(10000):\n",
    "    res = one_fwd(n)\n",
    "    overallError+=res[-1][0]\n",
    "    deriv = one_bkwd(res, n)\n",
    "    if(n % 1000 == 999):\n",
    "        print (\"Error:{:.4f}; Gradient:{:.5f}\".format(\n",
    "                overallError/1000, np.linalg.norm(deriv)))\n",
    "        overallError=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identical to the last keras rnn, but a GRU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "        GRU(n_hidden, return_sequences=True, input_shape=(cs, vocab_size),\n",
    "                  activation='relu', inner_init='identity'),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(oh_x_rnn, oh_y_rnn, batch_size=64, nb_epoch=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_nexts_oh(' this is')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Separate weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The theano GRU looks just like the simple theano RNN, except for the use of the reset and update gates. Each of these gates requires its own hidden and input weights, so we add those to our weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "W_h = id_and_bias(n_hidden)\n",
    "W_x = init_wgts(n_input, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "rW_h = init_wgts(n_hidden, n_hidden)\n",
    "rW_x = wgts_and_bias(n_input, n_hidden)\n",
    "uW_h = init_wgts(n_hidden, n_hidden)\n",
    "uW_x = wgts_and_bias(n_input, n_hidden)\n",
    "w_all = list(chain.from_iterable([W_h, W_y, uW_x, rW_x]))\n",
    "w_all.extend([W_x, uW_h, rW_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here's the definition of a gate - it's just a sigmoid applied to the addition of the dot products of the input vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gate(x, h, W_h, W_x, b_x):\n",
    "    return nnet.sigmoid(T.dot(x, W_x) + b_x + T.dot(h, W_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Our step is nearly identical to before, except that we multiply our hidden state by our reset gate, and we update our hidden state based on the update gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W_h, b_h, W_y, b_y, uW_x, ub_x, rW_x, rb_x, W_x, uW_h, rW_h):\n",
    "    reset = gate(x, h, rW_h, rW_x, rb_x)\n",
    "    update = gate(x, h, uW_h, uW_x, ub_x)\n",
    "    h_new = gate(x, h * reset, W_h, W_x, b_h)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Everything from here on is identical to our simple RNN in theano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "err=0.0; l_rate=0.1\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        l_rate *= 0.95\n",
    "        print (\"Error:{:.2f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make the previous section simpler and faster by concatenating the hidden and input matrices and inputs together. We're not going to step through this cell by cell - you'll see it's identical to the previous section except for this concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W = (shared(np.concatenate([np.eye(n_hidden), normal(size=(n_input, n_hidden))])\n",
    "            .astype(np.float32)), init_bias(n_hidden))\n",
    "\n",
    "rW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "uW = wgts_and_bias(n_input+n_hidden, n_hidden)\n",
    "W_y = wgts_and_bias(n_hidden, n_output)\n",
    "w_all = list(chain.from_iterable([W, W_y, uW, rW]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gate(m, W, b): return nnet.sigmoid(T.dot(m, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step(x, h, W, b, W_y, b_y, uW, ub, rW, rb):\n",
    "    m = T.concatenate([h, x])\n",
    "    reset = gate(m, rW, rb)\n",
    "    update = gate(m, uW, ub)\n",
    "    m = T.concatenate([h*reset, x])\n",
    "    h_new = gate(m, W, b)\n",
    "    h = update*h + (1-update)*h_new\n",
    "    y = nnet.softmax(T.dot(h, W_y) + b_y)\n",
    "    return h, T.flatten(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[v_h, v_y], _ = theano.scan(step, sequences=t_inp, \n",
    "                            outputs_info=[t_h0, None], non_sequences=w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upd_dict(wgts, grads, lr): \n",
    "    return OrderedDict({w: w-g*lr for (w,g) in zip(wgts,grads)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = nnet.categorical_crossentropy(v_y, t_outp).sum()\n",
    "g_all = T.grad(error, w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upd = upd_dict(w_all, g_all, lr)\n",
    "fn = theano.function(all_args, error, updates=upd, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "err=0.0; l_rate=0.01\n",
    "for i in range(len(X)): \n",
    "    err+=fn(np.zeros(n_hidden), X[i], Y[i], l_rate)\n",
    "    if i % 1000 == 999: \n",
    "        print (\"Error:{:.2f}\".format(err/1000))\n",
    "        err=0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6.0,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}